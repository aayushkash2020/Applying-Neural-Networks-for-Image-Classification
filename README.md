# Applying Neural Networks for Image Classification

## Overview

This project applies neural networks to the task of image classification using the CIFAR-10 dataset. The focus is on implementing, training, and evaluating custom deep learning models—including fully connected and convolutional architectures—in PyTorch. The work combines practical software engineering with machine learning fundamentals, emphasizing model performance, experimentation, and reproducibility.

---

## Dataset

- **CIFAR-10**: A well-known benchmark dataset containing 60,000 32x32 color images in 10 classes, with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images.

---

## Key Learning Objectives

- Build and train multilayer perceptron (MLP) models for image classification.
- Design and implement convolutional neural networks (CNNs) from scratch.
- Use PyTorch to define model architectures, data loaders, and training loops.
- Monitor learning dynamics through training and validation accuracy.
- Evaluate model performance using classification metrics and confusion matrices.
- Conduct experiments to compare architecture variants (e.g., MLP vs. CNN).
- Visualize learned filters and predictions to understand model behavior.
- Investigate the effects of hyperparameters such as learning rate and architecture depth.
- Apply best practices in neural network training, such as batching and regularization.
- Reflect on how deep learning models extract features from raw image data.

---

## Results Highlights

- Achieved significantly improved classification accuracy using CNNs over MLPs, illustrating the power of local receptive fields and weight sharing in image tasks.
- Demonstrated effective use of modular PyTorch components to train deep models.
- Visualized model predictions and misclassifications to better understand failure cases.
- Evaluated confusion matrices across architectures to highlight class-specific performance.
- Compared performance across models to understand the tradeoffs between depth, parameter count, and generalization.
- Documented training stability and convergence behavior under different learning rates and optimizers.

---

## Reflection

This project strengthened my understanding of neural networks for computer vision, from the fundamentals of matrix operations in fully connected networks to the architectural intuition behind CNNs. Through iterative experimentation and implementation in PyTorch, I gained insight into the role of architectural choices and training strategies in determining performance. The project also highlighted how deep models progressively learn useful visual features, even from raw pixel data.

---

## Contact

For questions or collaboration, reach out to aayushkashyap2018@gmail.com. Thank you!
